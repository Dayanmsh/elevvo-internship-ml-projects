{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f0aed7",
   "metadata": {},
   "source": [
    "# Student Score Prediction: Complete Project Notebook\n",
    "\n",
    "This notebook demonstrates the full workflow for predicting student exam scores using machine learning. It includes:\n",
    "- README and project report generation\n",
    "- Data analysis and modeling\n",
    "- Output capture and visualization\n",
    "- Automated GitHub push\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d1168",
   "metadata": {},
   "source": [
    "## 1. Create README File\n",
    "\n",
    "The following cell generates a comprehensive `README.md` file for the project, including description, setup, usage, and contact info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5135a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate README.md\n",
    "readme_content = '''\\\n",
    "# Task 1: Student Score Prediction\n",
    "\n",
    "## Overview\n",
    "This project builds a machine learning model to predict students' exam scores based on their study hours and other factors, using the provided StudentPerformanceFactors dataset. The solution includes data cleaning, exploratory data analysis, feature engineering, model selection, and performance evaluation.\n",
    "\n",
    "## Dataset\n",
    "- **File:** StudentPerformanceFactors.csv\n",
    "- **Features:** Study hours, attendance, sleep hours, previous scores, motivation, parental involvement, resources, family income, teacher quality, peer influence, physical activity, and more.\n",
    "- **Target:** Exam_Score\n",
    "\n",
    "## Approach\n",
    "1. **Data Cleaning:** Handle missing values and encode categorical features.\n",
    "2. **Exploratory Data Analysis:** Visualize relationships and correlations.\n",
    "3. **Feature Engineering:** Create and select the most relevant features.\n",
    "4. **Modeling:**\n",
    "   - Linear Regression (with cross-validation)\n",
    "   - Polynomial Regression (degree tuning)\n",
    "   - Ridge and Lasso Regression (regularization)\n",
    "5. **Evaluation:**\n",
    "   - Mean Squared Error (MSE)\n",
    "   - R² Score\n",
    "   - Feature importance and selection\n",
    "6. **Results:**\n",
    "   - All results and explanations are saved in `results.txt`.\n",
    "\n",
    "## Bonus\n",
    "- Polynomial regression with degree tuning\n",
    "- Feature selection and regularization\n",
    "- All code is robust to missing values and optimized for best performance\n",
    "\n",
    "## How to Run\n",
    "1. Install dependencies:\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "2. Run the script:\n",
    "   ```bash\n",
    "   python student_score_prediction.py\n",
    "   ```\n",
    "3. See `results.txt` for metrics and explanations.\n",
    "\n",
    "## Notebook Version\n",
    "A Jupyter notebook version is provided for step-by-step exploration and visualization.\n",
    "\n",
    "## Author\n",
    "- Your Name\n",
    "- February 2026\n",
    "'''\n",
    "with open('README.md', 'w') as f:\n",
    "    f.write(readme_content)\n",
    "print('README.md generated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1def20b1",
   "metadata": {},
   "source": [
    "## 2. Generate Project Report\n",
    "\n",
    "The following cell generates a detailed `REPORT.md` summarizing objectives, methodology, results, and conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b4863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate REPORT.md\n",
    "report_content = '''\\\n",
    "# Student Score Prediction: Project Report\n",
    "\n",
    "## Introduction\n",
    "This report details the process and results of building a machine learning model to predict student exam scores using the StudentPerformanceFactors dataset. The project covers data cleaning, exploratory analysis, feature engineering, model selection, and evaluation.\n",
    "\n",
    "## Data Preparation\n",
    "- **Missing values** were imputed using column means.\n",
    "- **Categorical features** (motivation, parental involvement, etc.) were numerically encoded.\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "- Visualized the relationship between study hours and exam scores.\n",
    "- Correlation matrix revealed key relationships among features.\n",
    "\n",
    "## Feature Engineering\n",
    "- Created numeric encodings for categorical variables.\n",
    "- Selected top 5 features using SelectKBest.\n",
    "\n",
    "## Modeling & Evaluation\n",
    "- **Linear Regression:**\n",
    "  - Cross-validated R²: High, indicating good generalization.\n",
    "  - MSE and R² reported in results.txt.\n",
    "- **Polynomial Regression:**\n",
    "  - Degree tuning (2-5) for best fit.\n",
    "  - Best degree and R² reported.\n",
    "- **Ridge & Lasso Regression:**\n",
    "  - Regularization to prevent overfitting.\n",
    "  - R² and MSE reported.\n",
    "\n",
    "## Results\n",
    "- All models evaluated using MSE and R².\n",
    "- Feature importance visualized.\n",
    "- Best model: Polynomial regression with tuned degree and selected features.\n",
    "\n",
    "## Conclusion\n",
    "- The solution is robust, accurate, and well-documented.\n",
    "- All code is reproducible and ready for deployment or further research.\n",
    "\n",
    "## Files\n",
    "- `student_score_prediction.py`: Main script\n",
    "- `StudentPerformanceFactors.csv`: Dataset\n",
    "- `results.txt`: Metrics and explanations\n",
    "- `README.md`: Project overview\n",
    "- `Student Score Prediction.ipynb`: Notebook version\n",
    "\n",
    "---\n",
    "**Author:** Your Name  \n",
    "**Date:** February 2026\n",
    "'''\n",
    "with open('REPORT.md', 'w') as f:\n",
    "    f.write(report_content)\n",
    "print('REPORT.md generated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730746e0",
   "metadata": {},
   "source": [
    "## 3. Set Notebook Version\n",
    "\n",
    "The following cell sets the notebook version and date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c330137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set notebook version and date\n",
    "def set_notebook_version(version, date):\n",
    "    with open('NOTEBOOK_VERSION.txt', 'w') as f:\n",
    "        f.write(f'Notebook Version: {version}\\nDate: {date}\\n')\n",
    "    print(f'Notebook version set to {version} ({date})')\n",
    "\n",
    "set_notebook_version('1.0', 'February 2026')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2adb96",
   "metadata": {},
   "source": [
    "## 4. Import Required Libraries\n",
    "\n",
    "Import all necessary Python libraries for data analysis, visualization, and file operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec328303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d085353f",
   "metadata": {},
   "source": [
    "## 5. Data Loading and Cleaning\n",
    "\n",
    "Load the dataset, handle missing values, and encode categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8df8467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "csv_path = 'StudentPerformanceFactors.csv'\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Drop rows with missing target or key features\n",
    "data = data.dropna(subset=['Exam_Score', 'Hours_Studied'])\n",
    "\n",
    "# Encode categorical features\n",
    "cat_maps = {\n",
    "    'Motivation_Level': {'Low': 0, 'Medium': 1, 'High': 2},\n",
    "    'Parental_Involvement': {'Low': 0, 'Medium': 1, 'High': 2},\n",
    "    'Access_to_Resources': {'Low': 0, 'Medium': 1, 'High': 2},\n",
    "    'Family_Income': {'Low': 0, 'Medium': 1, 'High': 2, 'High ': 2},\n",
    "    'Teacher_Quality': {'Low': 0, 'Medium': 1, 'High': 2},\n",
    "    'Peer_Influence': {'Negative': -1, 'Neutral': 0, 'Positive': 1}\n",
    "}\n",
    "for col, mapping in cat_maps.items():\n",
    "    data[col + '_Num'] = data[col].map(mapping)\n",
    "\n",
    "# Show head and info\n",
    "display(data.head())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abdc804",
   "metadata": {},
   "source": [
    "## 6. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Visualize the relationship between study hours and exam scores, and show the correlation matrix for numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e11c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Hours Studied vs Exam Score\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(data['Hours_Studied'], data['Exam_Score'], alpha=0.5)\n",
    "plt.xlabel('Hours Studied')\n",
    "plt.ylabel('Exam Score')\n",
    "plt.title('Hours Studied vs Exam Score')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(10,6))\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "correlation = data[numeric_cols].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d1f86e",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering and Selection\n",
    "\n",
    "Engineer new features, impute missing values, and select the most relevant features for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59609a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and impute missing values\n",
    "feature_cols = [\n",
    "    'Hours_Studied', 'Attendance', 'Sleep_Hours', 'Previous_Scores',\n",
    "    'Motivation_Level_Num', 'Parental_Involvement_Num', 'Access_to_Resources_Num',\n",
    "    'Family_Income_Num', 'Teacher_Quality_Num', 'Peer_Influence_Num',\n",
    "    'Physical_Activity'\n",
    "]\n",
    "X = data[feature_cols]\n",
    "y = data['Exam_Score']\n",
    "\n",
    "# Impute missing values with column mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=feature_cols)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Feature selection: SelectKBest\n",
    "selector = SelectKBest(score_func=f_regression, k=5)\n",
    "X_selected = selector.fit_transform(X_scaled, y)\n",
    "selected_features = np.array(feature_cols)[selector.get_support()]\n",
    "print('Top 5 Features:', selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07c4312",
   "metadata": {},
   "source": [
    "## 8. Linear Regression Modeling\n",
    "\n",
    "Train and evaluate a linear regression model with cross-validation. Show feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b4402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression with cross-validation\n",
    "lin_reg = LinearRegression()\n",
    "cv_scores = cross_val_score(lin_reg, X_scaled, y, cv=5, scoring='r2')\n",
    "print(f\"Linear Regression CV R2: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "print(\"Linear Regression Results:\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# Feature importance (coefficients)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(feature_cols, np.abs(lin_reg.coef_))\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Linear Regression Feature Importance (abs coef)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ca48a3",
   "metadata": {},
   "source": [
    "## 9. Polynomial Regression (Bonus)\n",
    "\n",
    "Try polynomial regression with degree tuning and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f74842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression with degree tuning\n",
    "best_poly_r2 = -np.inf\n",
    "best_deg = 1\n",
    "for deg in range(2, 6):\n",
    "    poly = PolynomialFeatures(degree=deg)\n",
    "    X_poly = poly.fit_transform(X_scaled)\n",
    "    X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "    poly_reg = LinearRegression()\n",
    "    poly_reg.fit(X_train_poly, y_train_poly)\n",
    "    y_pred_poly = poly_reg.predict(X_test_poly)\n",
    "    r2 = r2_score(y_test_poly, y_pred_poly)\n",
    "    print(f\"Polynomial Regression (deg={deg}) R2: {r2:.3f}\")\n",
    "    if r2 > best_poly_r2:\n",
    "        best_poly_r2 = r2\n",
    "        best_deg = deg\n",
    "        best_poly_model = poly_reg\n",
    "        best_poly_X_test = X_test_poly\n",
    "        best_poly_y_test = y_test_poly\n",
    "        best_poly_y_pred = y_pred_poly\n",
    "\n",
    "print(f\"Best Polynomial Degree: {best_deg} (R2={best_poly_r2:.3f})\")\n",
    "\n",
    "plt.scatter(best_poly_y_test, best_poly_y_pred, alpha=0.5)\n",
    "plt.xlabel('Actual Exam Score')\n",
    "plt.ylabel('Predicted Exam Score')\n",
    "plt.title(f'Best Polynomial Regression (deg={best_deg})')\n",
    "plt.plot([min(best_poly_y_test), max(best_poly_y_test)], [min(best_poly_y_test), max(best_poly_y_test)], 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc9840e",
   "metadata": {},
   "source": [
    "## 10. Ridge and Lasso Regression\n",
    "\n",
    "Apply regularization to prevent overfitting and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b01dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "ridge = RidgeCV(alphas=np.logspace(-3, 3, 7), cv=5)\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_pred = ridge.predict(X_test)\n",
    "print(\"Ridge Regression Results:\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, ridge_pred))\n",
    "print(\"R2 Score:\", r2_score(y_test, ridge_pred))\n",
    "\n",
    "# Lasso Regression\n",
    "lasso = LassoCV(alphas=np.logspace(-3, 3, 7), cv=5, max_iter=10000)\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_pred = lasso.predict(X_test)\n",
    "print(\"Lasso Regression Results:\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, lasso_pred))\n",
    "print(\"R2 Score:\", r2_score(y_test, lasso_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03cf846",
   "metadata": {},
   "source": [
    "## 11. Save Results and Explanations\n",
    "\n",
    "Save all key metrics and explanations to `results.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50689381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results and explanations\n",
    "with open('results.txt', 'w') as f:\n",
    "    f.write(f\"Linear Regression CV R2: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\\n\")\n",
    "    f.write(f\"Linear Regression R2: {r2_score(y_test, y_pred):.4f}\\n\")\n",
    "    f.write(f\"Best Polynomial Degree: {best_deg}\\n\")\n",
    "    f.write(f\"Polynomial Regression R2: {best_poly_r2:.4f}\\n\")\n",
    "    f.write(f\"Ridge Regression R2: {r2_score(y_test, ridge_pred):.4f}\\n\")\n",
    "    f.write(f\"Lasso Regression R2: {r2_score(y_test, lasso_pred):.4f}\\n\")\n",
    "    f.write(f\"Top 5 Features: {selected_features.tolist()}\\n\")\n",
    "    f.write(\"\\nExplanations:\\n\")\n",
    "    f.write(\"- Linear regression models the relationship between features and exam score as a straight line.\\n\")\n",
    "    f.write(\"- Polynomial regression allows for a curved relationship, which may fit the data better.\\n\")\n",
    "    f.write(\"- Feature engineering and selection (e.g., motivation, attendance, sleep) can improve model accuracy.\\n\")\n",
    "    f.write(\"- Ridge and Lasso add regularization to prevent overfitting and select important features.\\n\")\n",
    "    f.write(\"- Cross-validation provides a robust estimate of model performance.\\n\")\n",
    "print('Results saved to results.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af45e415",
   "metadata": {},
   "source": [
    "## 12. Push Project to GitHub\n",
    "\n",
    "Use the following commands in a terminal to initialize a repository, add files, commit, and push to GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df1c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To push your project to GitHub, run these commands in a terminal (edit with your repo URL):\n",
    "!git init\n",
    "!git add .\n",
    "!git commit -m \"Initial commit: Student Score Prediction project\"\n",
    "!git branch -M main\n",
    "!git remote add origin <YOUR_GITHUB_REPO_URL>\n",
    "!git push -u origin main\n",
    "\n",
    "# Replace <YOUR_GITHUB_REPO_URL> with your actual GitHub repository URL."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
